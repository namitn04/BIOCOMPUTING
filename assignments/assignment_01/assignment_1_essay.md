I’ve been interested in bioinformatics since high school. I attended a magnet program for medical sciences, but was mortified by the thought of becoming a doctor. I’d always preferred computer science and engineering, but my parents nudged me to branch out. Thank God they did, because my first real exposure to bioinformatics came in a class called “Genetics & Biotech,” where I read Genome by Matt Ridley. This primer into genetics and synthetic biology completely shifted how I saw the body. It suddenly felt like we could be picked apart and rebuilt at the finest level.

At W&M, I waddled my way through a few labs before finding my footing. My first “bioinformatics” project was parsing soil nutrient data in Python with Jupyter notebooks… painful enough that I briefly thought bioinformatics wasn’t for me. Then I joined iGEM, got thrown to the cluster-computing wolves, and taught myself the stack. I ended up building a bioinformatics pipeline to discover bacteriophage satellites all by myself. That became SaPhARI and it was an unforgettable experience, especially when it was nominated for Best Software Tool at the iGEM Grand Jamboree! Still, I worried that staying on the iGEM team and in dry-lab would limit me.

When Dr. Mitra joined Applied Science, I was immediately drawn in. The idea of designing synthetic tools and implants for regenerative medicine fed the same curiosity that started back in high school. I pivoted into his lab for my Honors thesis, where I am now focused almost entirely on wet-lab work: developing a dual-secretome 3D-printed scaffold to promote chondrogenic differentiation of stem cells in diabetic conditions. While this has given me valuable hands-on experience, I know I ultimately want my future to be a true mix of both wet-lab and computational work… maybe systems biology, maybe bioengineering, maybe something adjacent. Whatever the program, I want cluster computing in the picture.

For this course, my goals are basic: strengthen my linux+git fundamentals and take reproducibility seriously. iGEM taught me the hard way. Debugging my own command line and Conda problems ate up something like a third of the entire project. If I’m going to take my software to publication and make more that are genuinely useful, I need more reps building things other people can actually run (my main plan of attack).

The current folder structure mainly comes from lessons I also learned the hard way. I keep “raw” and “ready” data separate so I don’t overwrite downloads and so I can always trace what preprocessing I did. Same with “raw” and “filtered” outputs, tools like DIAMOND spit out way too much, and I usually just want the top hit or something cleaner to work with. The docs and logs are there so I don’t forget what environment I used or what parameters I ran, which has burned me before. And splitting scripts into Python and shell just reflects how I actually work (I prefer to use Python, but I know we will be using mostly shell scripts in this class).

The biggest lesson I’ve taken from doing bioinformatics is that nothing matters if it isn’t reproducible. Science depends on that, but with code it becomes especially clear. Karl Popper once said, “Single occurrences that cannot be reproduced are of no significance to science.” From my own experience, I’ve realized how hard it is to run other people’s software without clear instructions or a good config file. When I made sloppy environments in the past, it was basically impossible for someone else to set things up without spending hours debugging. Bioinformatics makes this even more important because running pipelines on huge datasets takes so much time. If something breaks or isn’t written down, you can waste days or even weeks. In my opinion, bioinformatics is probably the only kind of science that can be truly reproducible down to the finest detail. Unlike wet lab work, where it’s impossible to control every tiny variable, code can always be rerun exactly as it was. That’s why keeping environments, logs, and scripts documented is so important.

